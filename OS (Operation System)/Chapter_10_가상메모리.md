# 0. Introduction

> 1. [요구 페이징](#1-요구-페이징)
> 2. [페이지 교체](#2-페이지-교체)
> 3. [페이지 프레임의 할당](#3-페이지-프레임의-할당)
> 4. [전역 교체와 지역 교체](#4-전역교체와-지역교체)
> 5. [스레싱](#5-스레싱)

<br>

- 해당 내용은 [운영체제와 정보기술의 원리 -반효경 지음-](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791158903589&orderClick=LAG&Kc=) 와 [kocw 이화여자대학교 운영체제 - 반효경 교수 -](http://www.kocw.net/home/cview.do?lid=3dd1117c48123b8e)를 보고 정리한 내용이다.
- 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.

<br>

운영체제는 보통 모든 프로그램들에 공평하게 같은 크기의 메모리를 할당하기보다는 몇몇 프로그램들에게 집중적으로 메모리를 할당한 후, 시간이 흐르면 이들로부터 메모리를 회수해서 다른 프로그램들에게 다시 집중적으로 메모리를 할당하는 방식을 채택한다.

왜냐하면 프로세스의 빠른 수행을 위해 프로그램마다 최소한 확보해야하는 메모리 크기가 존재하기 때문이다.

하지만 그렇다고 프로세스의 주소 공간 전체가 메모리에 올라와 있어야 하는 것은 아니다. 운영체제는 CPU에서 당장 수행할 부분만을 메모리에 올려놓고, 그렇지 않은 부분은 disk의 swap area에 내려놓았다가 다시 필요해지면 메모리에 올라가 있는 부분과 교체하는 방식을 사용한다. 그래서 물리적 메모리 크기에 대한 제약을 생각 필요가 없어진다.

또한, 프로그램은 0번지부터 시작하는 자기 자신만의 메모리 공간을 가정한다. 이러한 공간을 `Virtual memory(가상 메모리)` 이라 한다. 이 가상 공간 중 일부가 swap area에존재하고, 일부는 물리적 메모리에 존재하는 것이다.

이 가상 메모리를 적재하는 단위에 따라 `요구 페이징` 또는 `요구 세그먼테이션` 방식으로 나눠진다. 전자는 대부분의 경우에 사용되며, 세부적인 구현에 특히 사용된다. 후자는 `paged segmentation` 기법을 사용하는 경우를 말한다.

그러면 요구 페이징에 대해 먼저 알아보자.

<br>

---

# 1. 요구 페이징

- 요구 페이징이란?
  - 프로그램 실행 시, 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 게 아닌, 당장 사용될 페이지만을 올리는 방식
  - 그래서, 특정 페이지에 대한 CPU 요청이 들어온 후에야 해당 페이지를 메모리에 적재한다.
  - 비유
    - 매 끼니마다 필요한 분량만큼 재료를 구입해서 보관하는 방식
    - 냉장고: 물리적 메모리
    - 식재료: 프로세스를구성하는 페이지
    - 보관 행위: 페이지를 메모리에 적재
- 장점
  - 필요한 부분만을 적재하기 때문에, 메모리 사용량 감소 + 프로세스 전체를 메모리에 올리는데 소요되는 입출력 오버헤드 감소
  - 응답시간 단축
  - 더 많은 프로세스수용
  - 물리적 메모리 용량 제약에서 벗어남
- Problem
  - 가상 메모리 중 어떤 페이지가 메모리에 존재하는지 유무를 구별하기 위한 방안 필요
- Solution
  - 유효-무효(Valid - Invalid bit)를 두어 page가 각 memory에 존재하는지 표시
  - 모든 page에 대해 존재해야 하므로, page table의각 항목별로 저장
- Valid - Invalid bit
  - 기본 bit 값: invalid bit
  - 특정 페이지가 참조되어 메모리에 적재 → Valid bit → 적재된 page가 swap area로 쫓겨남 → Invalid bit
  - Invalid bit 는 언제일 때를 말하는가?
    - 해당 페이지가 메모리에 없는 경우
    - 페이지가 속한 주소 영역을 프로세스가 사용하지 않은 경우
- Page fault
  - CPU가 한 페이지를 참조하려는데, 현재 메모리에 없어서 invalid bit인 상태

## 1) 요구 페이징의 페이지 부재 처리

<그림 8-2> 페이지 부재를 처리하는 과정

- CPU에 무효 페이지에 접근 → 주소 변환 담당 MMU가 페이지 부재 트랩(page fault trap) 발생 → kernel mode로 전환 → OS의 페이지 부재 처리루틴(page fault handler)이 호출
- OS는 프로세스의 해당 페이지에 대한 접근이 적법한지 먼저 체크
  - 사용되지 않는 주소 영역에 속한 페이지에 접근하려거나, 해당 페이지에 대한 접근 권한 위반(protection violation)을 했을 경우, 해당 프로세스를 종료
    - protection violtaion: read-only file에 write 시도를 한 경우
- 적법 판정 → 물리적 메모리의 빈 frame을 할당받아 이 공간에 해당 페이지를 적재.
  - 빈 frame이 없다면, 물리적 메모리에 적재된 페이지 중 하나를 swap out
- 요청한 페이지를 디스크로부터 물리적 메모리에 적재하기까지 오랜 시간이 걸리므로, CPU를빼앗기고 봉쇄 상태가 됨
- 현재까지 수행되던 프로세스는 CPU register state 및 PC value를 PCB에 저장하여, 나중에 이 프로세스를 재할당 받았을 때, 정확히 같은 상태에서 다음 명령(instruction)을 수행하도록 한다.
- I/O 작업이 완료되어 interrupt가 발생하면 page table에서 해당 page의 valid-invalid bit를 valid bit로 설정
- 봉쇄된 process를 ready queue로 이동

## 2)요구 페이징의 성능

- 페이지 부재의 발생 빈도
  - 페이지 부재가 발생하면 요청된 페이지를 디스크로부터 물리적 메모리로 읽어오는 막대한 overhead가 발생
  - 물리적 메모리에 올라와 페이지 중 하나를 swap out 후, swap area에 있는 요청된 페이지를 메모리로 읽어 온 후, interrupt를 통해 프로세스가 실행을 재개할 수 잇는 상태로 바꾸어주고, 자신의 차례가 되면 문맥 교환을 통해 다시 CPU를 얻는다.
  - 위 과정에서 disk input/output과 각종 overhead가 포함되어 시간이 오래 걸린다.
  - `유효 접근 시간`이 짧을 수록 성능 향상

<br>

---

# 2. 페이지 교체

- 페이지 교체(page replacement)란?
  - 페이지 부재가 발생했을 때, 요청된 페이지를 디스크에서 메모리로 불러오기 위에 메모리에 적재된 여러 페이지 중 하나를 swap out하여 요청된 페이지를 메모리에 적재하는 것
  - 그리고, 교체할 때 어떤 프레임에 있는 페이지를 쫓아낼 것인지 결정하는 알고리즘을 `교체 알고리즘(replacement algoritum)` 이라 한다.
    - 이 알고리즘의 목표: 페이지 부재를 최소화하는 것
    - 가까운 미래에 참조될 가능성이 적은 페이지를 내쫓는 것이 성능 향상 방안
- 페이지 참조열: 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것

## 1) 최적 페이지 교체

- Belady’s optimal algorithum (빌레디의 최적 알고리즘) = MIN, OPT
  - 페이지 부재율을 최소화하기 위해, 메모리에 존재하는 페이지 중 가까운 미래에 참조될 페이지를 쫓아내는 것

<그림 8-4>

- 예시
  - 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
  - 처음 페이지 참조 시에는 4회까지 페이지 부재가 불가피하다.
  - 5, 6회는 이미 페이지가 존재하기 때문에 발생하지 않는다.
  - 7회에서 페이지 5를 참조 시, 페이지 부재가 발생하여 디스크에서 메모리로 가져오는 작업이 필요하다. 이 때 페이지 교체를 해야 하는데, 가장 먼 미래에 참조될 페이지인 4번 페이지와 교체된다.
  - 그래서 총 6번의 페이지 부재가 발생한다.
- **_미래에 어떤 페이지가 참조될지 미리 알고 있다는 전제_** 이므로, 온라인에서 사용할 수 없다.
- 그래서, 오프라임 알고리즘이라 한다.
- 어떠한 알고리즘보다도 **_가장 적은 페이지 부재율을 보장_** 하므로 다른 알고리즘 성능에 대한 **_상한선(Upper bound)_** 를 제공한다.
- 그래서 어떤 교체 알고리즘이 이 알고리즘과 유사하다면 더 이상의 알고리즘 연구가 필요하지 않음을 시사한다.

## 2) 선입선출(FIFO:First In First Out) 알고리즘

- 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓는 알고리즘
  - 향후 참조 가능성 고려 X
  - 물리적 메모리에 들어온 순서대로 대상 선정

< 그림 8 -5 >

- 페이지 프레임 3개
  - 9번의 페이지 부재
- 페이지 프레임 4개
  - 10번의 페이지 부재

## 3) LRU(Least Recently Used) 알고리즘

- 시간지역성(Temporal locality)이 낮은 페이지를 쫓아내는 알고리즘
  - 시간 지역성: 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질
  - 마지막 참조 시점이 가장 오래된 페이지를 교체하는 것

<그림 8-6>

## 4) LFU(Least Frequently used) 알고리즘

<그림 8-7>

- 페이지의 참조 횟수로 교체시킬 페이지를 결정
  - 물리적 메모리 내에 존재하는 페이지 중에서 과거에 참조 횟수(reference count)가 가장 적은 페이지로 교체 페이지를 결정하는 알고리즘
  - 최저 참조 횟수를 가진 페이지가 여러 개일 경우, 상대적으로 더 오래전에 참조된 페이지를 쫓아내는 게 효율적이다.
- 참조 횟수를 계산하는 방식에 따라 `Incache-LFU` 와 `Perfect-LFU` 로 나눠진다.
- Incache - LFU

  - page가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식
  - 그래서 메모리에서 내려갔다가 다시 적재되면 참조 횟수는 초기화된다.

- Perfect - LFU
  - 메모리에 적재여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트하는 방식
  - 장점: 페이지의 참조 횟수를 정확히 반영
  - 단점: 메모리에서 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로, 오버헤드가 상대적으로 더 크다.
- LFU 알고리즘은 LRU알고리즘보다 오랜 시간 참조 기록을 반영
  - 참조 횟수를 통해 장기적인 시간 규모에서의 참조 성향을 고려
  - 시간에 따른 페이지 참조 변화를 반영 X
  - LRU보다 구현 복잡

## 5) 클럭(Clock) 알고리즘(Question)

- 하드웨어적 지원을 통해 알고리즘의 운영 오버헤드를 줄인 방식
  - 그래서 LRU 비해 페이지의 관리가 훨씬 빠르고 효율적으로 이뤄진다.
  - 그래서 대부분의 페이지 교체 알고리즘으로 클럭 알고리즘을 선택한다.
- LRU를 근사시킨 알고리즘으로 NUR(Not Used Recently) 또는 NRU(Not Recently Used) 알고리즘으로도 불린다.
- LRU는 가장 오래 전에 참조된 페이지를 교체하는 것에 비해 클럭 알고리즘은 오랫동안 참조되지 않은 페이지 중 하나를 교체하기 때문에, 가장 오래되었다는 건 보장하지 못한다.
- 교체할 페이지 선정을 위해 **_페이지 프레임들의 참조 비트(reference bit)_** 를 순차적으로 조사한다.
  - 참조 비트는 각 프레임마다 하나씩 존재한다.
  - 그 프레임 내의 페이지가 참조될 때, 하드웨어에 의해 1로 자동 세팅된다.
  - 그래서, 참조 비트가 1인 페이지는 0으로 바꾼 후 지나가고, 참조비트가 0인 페이지는 교체되고 1로 세팅
  - 시계바늘이 한 바퀴 도는 동안 이 교체된 페이지가 다시 참조되지 않으면 0으로 바꾼 후, 교체하지 않고 그냥 지나간다.
  - 모든 페이지 프레임 조사를 완료하면 다시 반복한다.

<그림 8-8>

- 2차 기회(second chance) 알고리즘

<br>

---

# 3. 페이지 프레임의 할당

프로세스 여러 개가 동시에 수행되는 상황에서 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정해야 한다. 이를 위한 알고리즘을 3가지로 나눌 수 있다.

- 첫 번째, 균등할당(equal algorithum)
  - 모든 프로세스에게 페이지 프레임을 균일하게 할당하는 방식
- 두 번째, 비례할당(proportional allocation)
  - 프로세스의 크기에 비례해서 페이지 프레임을 할당하는 방식
- 세 번째, 우선순위 할당(priority allocation)
  - 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당하는 방식
  - 당장 CPU에서 실행될 프로세스와 아닌 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당하는 방식

하지만, 할당 알고리즘 만으로는 process의 페이지 참조 특성을 제대로 반영하지 못한다. 페이지 참조 특성에 대해 알아보자.

- 첫 번째, 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야 한다.
- 두 번째, 반복문을 실행 중인 경우에는 반복문을 구성하는 페이지들을 한꺼번에 메모리에 올려놓는 게 유리하다.
- 세 번째, 프로세스에게 최소한으로 필요한 메모리의 양은 시간에 따라 다르다.

**_그래서, 종합적인 상황을 고려해서 각 프로세스에 할당되는 페이지 프레임의 수를 결정해야 한다._**

경우에 따라서는, 최소한의 메모리 요구량을 충족시키기 위해 일부 프로세스에게 메모리를 할당하지 않아야 한다.

<br>

---

# 4. 전역교체와 지역교체

교체할 페이지를 선정할 때, 교체 대상이 될 프레임의 범위를 결정하는 방법

- 전역 교체(global replacement)
  - 모든 페이지 프레임이 교체 대상이 될 수 있는 방법
  - 프로세스마다 할당하는 게 아닌, 전체 메모리를 각 프로세스가 공유해서 사용하고, 교체 알고리즘에 근거해서 할당 메모리 양이 가변적으로 변하는 방법
  - LRU, LFU, clock 등의 알고리즘을 물리적 메모리 내에의 전체 페이지 프레임들을 대상으로 적용하는 경우
- 지역 교체(local replacement)
  - 현재 수행 중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정하는 방법
  - 프로세스마다 페이지 프레임을 미리 할당하는 것
  - 알고리즘을 프로세스 별로 독자적으로 운영할 때에는 지역 교체 방법이 된다.

<br>

---

# 5. 스레싱

## 1) 워킹셋(working-set) 알고리즘

## 2) 페이지 부재 빈도(page fault frequency: PFF) 알고리즘

<br>

---

# Reference

- [kocw 이화여자대학교 운영체제 - 반효경 교수 -](http://www.kocw.net/home/cview.do?lid=3dd1117c48123b8e)
- [운영체제와 정보기술의 원리 - 반효경 지음 -](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791158903589&orderClick=LAG&Kc=)
